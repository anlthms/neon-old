# Experiment settings to train/test a CNN on MNIST.

!obj:neon.experiments.fit_predict_err.FitPredictErrorExperiment {

  dataset: &ds !obj:datasets.Imageset {
    repo_path: '/usr/local/data',
    save_dir: '/usr/local/data/CIFAR10/cifar-macro/train',
    cropped_image_size: &cis 32,
    output_image_size: *cis,
    # max_tar_file: &mtf 1000,
    output_batch_size: 10000,
    ring_buffer_size: 3,
    num_processes: 3,
    num_train_macro_batches: 5, #max available train macro_batches
    num_val_macro_batches: 1, #max available val macro batches
    # macro batch start and end indices to use for train and val datasets
    start_train: 1,
    end_train: 2,
    start_val: 0,
    end_val: 1,
  },

  weight_inits: &wt_init !obj:params.UniformValGen {
    low: -0.1,
    high: 0.1,
  },

  lrule: &gdm {
    type: gradient_descent_momentum,
    lr_params: {
      learning_rate: 0.01,
      momentum_params: {
        type: constant,
        coef: 0.90,
      },
    },
  },

  # CNN model specification
  # essentially a multi-layer perceptron with convolutional and pooling layers
  model: !obj:models.MLP {
    num_epochs: 10,
    batch_size: &bs 100,
    layers: [
      &datalayer !obj:layers.ImageDataLayer {
        name: d0,
        is_local: True,
        nofm: 3,
        ofmshape: [32, 32],
      },
      !obj:layers.ConvLayer {
        name: layer1,
        lrule_init: *gdm,
        weight_init: *wt_init,
        nofm: 16,
        fshape: [5, 5],
      },
      !obj:layers.PoolingLayer {
        name: layer2,
        op: 'max',
        fshape: [2, 2],
        stride: 2,
      },
      !obj:layers.CrossMapResponseNormLayer {
        name: layer3,
        ksize: 5,
        alpha: 0.001,
        beta: 0.75,
      },
      !obj:layers.ConvLayer {
        name: layer4,
        lrule_init: *gdm,
        nofm: 32,
        fshape: [5, 5],
        weight_init: *wt_init,
      },
      !obj:layers.PoolingLayer {
        name: layer5,
        op: 'max',
        fshape: [2, 2],
        stride: 2,
      },
      !obj:layers.CrossMapResponseNormLayer {
        name: layer5b,
        ksize: 5,
        alpha: 0.001,
        beta: 0.75,
      },
      !obj:layers.FCLayer {
        name: layer6,
        nout: 500,
        lrule_init: *gdm,
        weight_init: *wt_init,
        activation: !obj:transforms.RectLin {},
      },
      &lastlayer !obj:layers.FCLayer {
        name: output,
        lrule_init: *gdm,
        weight_init: *wt_init,
        nout: 10,
        activation: !obj:transforms.Logistic {},
      },
      &costlayer !obj:layers.CostLayer {
        name: cost,
        ref_layer: *datalayer,
        ref_label: 'labels',
        raw_label: True,
        cost: !obj:transforms.CrossEntropy {},
      },
    ],
  },

  # logging options that are passed to logging.basicConfig
  # level value thresholds (set level lower to display them):
  #   CRITICAL 50
  #   ERROR    40
  #   WARNING  30
  #   INFO     20
  #   DEBUG    10
  #   NOTSET    0
  logging: {
    level: 20,
    format: '%(asctime)-15s %(levelname)s:%(module)s - %(message)s'
  },
}
